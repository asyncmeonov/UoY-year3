THE FIT:
Inference for Stan model: anon_model_9790f054c871d5c63975f7675febeee4.
4 chains, each with iter=1000; warmup=500; thin=1; 
post-warmup draws per chain=500, total post-warmup draws=2000.

             mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat
alpha      817.86  142.03 317.59  309.6 559.01  807.3 1052.1 1504.9      5   2.36
beta[0]    297.32   55.66 124.45  53.82 221.12 288.86 375.87 538.13      5   1.89
beta[1]      1.71    0.55   1.45  -2.45   0.95   1.82   2.61   4.19      7    1.5
beta[2]    -45.03     7.7  17.21 -75.75 -55.81 -45.72 -35.59  -9.91      5   1.95
beta[3]     -0.07    0.13    0.3  -0.71  -0.26  -0.05   0.14   0.53      5   1.58
beta[4]    1389.9  566.77 981.67 -167.9 822.76 1225.5 2130.7 3604.4      3   2.41
beta[5]    1617.5  181.25 543.75 544.54 1228.6 1639.8 2013.2 2607.2      9   1.46
beta[6]    434.15  284.88 493.42 -320.3  74.15 403.28 579.38 1570.3      3   2.97
beta[7]     -1509  337.46 754.58  -2864  -2124  -1490 -837.5 -167.3      5    1.7
beta[8]    211.79   73.07 242.36 -260.2  45.21 177.09 376.33 761.32     11   1.55
beta[9]     -2564  1005.0 1740.8  -6707  -3515  -2433  -1000 -95.69      3   2.34
beta[10]   -953.6  157.61 352.43  -1762  -1215 -870.1 -702.6 -384.4      5   2.24
beta[11]    -6.13   10.19  17.65 -29.93 -19.52 -11.15   4.26  31.99      3   2.57
beta[12]    51.32   11.52  25.76  12.72  33.68  49.17  64.26 117.75      5   1.99
beta[13]     3.09    0.58   1.29   0.32   2.24   3.06   4.13   5.36      5   1.36
beta[14]   -265.9  698.58 2095.7  -4472  -1153 -526.7 837.35 5516.4      9   1.72
beta[15]   3154.4  1127.4 1952.7 -181.3 1253.8 3282.6 4484.8 6850.4      3   2.34
beta[16]   866.75  569.27  986.0 -92.88 101.56 526.62 1421.1 3532.9      3    3.0
beta[17]    -1396  1665.9 2885.4  -9609  -1811 -326.4 416.36 1928.7      3   2.97
beta[18]   -699.4   360.7 721.39  -2458  -1051 -561.4 -170.6 376.47      4   1.51
beta[19]   1103.8  566.81 1133.6 -555.7 134.02 991.16 1854.3 3569.1      4   2.01
beta[20]    30.68   10.54  25.82  -8.86  14.42   24.7  38.57  90.44      6   1.68
beta[21]    -5.88    0.76   1.87 -10.05   -7.0  -5.84  -4.54  -2.73      6   1.94
beta[22]    -9.31    2.26   4.53 -19.23 -12.31  -8.44  -5.69  -3.15      4   2.45
beta[23]      0.1    0.06   0.15  -0.21  -0.01   0.13   0.21   0.37      6   1.54
beta[24]    -1145  147.39 389.97  -1732  -1453  -1207 -891.7 -241.2      7   1.67
beta[25]   416.01   85.14 190.38 131.95 262.41  391.3 524.79 857.96      5   1.89
beta[26]   -504.0   61.22 161.98 -813.9 -640.4 -474.7 -371.0 -260.0      7   2.07
beta[27]   -705.3  193.51 387.01  -1649 -860.9 -633.2 -460.2 -45.62      4   1.94
beta[28]   -107.1   44.04 152.55 -449.2 -181.2 -120.2 -36.62 245.21     12   1.55
beta[29]    -1310  339.33 678.66  -2611  -1830  -1386 -626.8 -277.5      4   1.83
--- removed predictions for y ---
lp__        -6.75     0.7   3.29 -14.44  -8.58  -6.25  -4.33  -1.82     22   1.15

Samples were drawn using NUTS at Tue Feb 18 14:15:51 2020.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).

<class 'numpy.ndarray'>
(114,)
(114,)
[1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 0 1 0
 1 0 1 0 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 1
 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 0
 1 0 1]
[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0.
 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0.
 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.
 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.
 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1.]
             precision    recall  f1-score   support

  malignant       0.90      0.90      0.90        50
     benign       0.92      0.92      0.92        64

avg / total       0.91      0.91      0.91       114

[[45  5]
 [ 5 59]]
(45, 5, 5, 59)

